{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trophic Information Pipeline Readme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "The following cells in concert work to create a trophic information pipeline run in a Jupyter notebook to create a file that has the final classifications for scientific names found within research articles.\n",
    "\n",
    "**Getting Started**\n",
    "To run this notebook, the libraries that are imported must be on your machine. The Ollie tool must be downloaded from  http://knowitall.cs.washington.edu/ollie/ollie-app-latest.jar as well as the English MaltParser model (engmalt.linear-1.7.mco) http://www.maltparser.org/mco/english_parser/engmalt.html based on the instructions from https://github.com/knowitall/ollie. The two downloads should be in the same folder as the jupyter notebook file. The scientific names file, the common names file, the abbreviated scientific names file, the english words file, the Random Forest training file and the trophic keywords file must be downloaded from https://github.com/JSRaffing/Trophic-Information-Extraction-Pipeline and all kept in the same folder as the previous downloaded mentioned. Once that is complete fill in the necessary names in the Part 1 cell which are the names of the files to be analyzed (PDFs), and the name of the result file. All other variables are left as the defaults based on the downloaded file names. If you change a file or a file name, the default must be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Filling in the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to be analyzed: replace the example file names with the names of your actual pdfs\n",
    "files_to_be_analyzed = ['example_file1.pdf', 'example_file2.pdf', 'example_file3.pdf']\n",
    "# Result file name: replace the example result file name with the name of the file you want\n",
    "output_file = 'Name_of_Result_File.txt'\n",
    "# English words File: To change the file, replace 'words.txt' with the name of your file that is structured with one word on each line.\n",
    "english_dict_file = 'words.txt'\n",
    "# Scientific Names File: # To change the file, replace 'scinames-final.txt' with the name of your file that has each scientific name on a row in the first column and the corresponding kingdom on the same row in the second column\n",
    "sci_names_file = 'scinames-final.txt'\n",
    "# Common Names File: # To change the file, replace 'comnames-final.txt' with the name of your file that has each common name on a row in the first column and the corresponding kingdom on the same row in the second column\n",
    "common_names_file = 'comnames-final.txt'\n",
    "# Abbreviated Scientific Name File: # To change the file, replace 'acronamesflipped-may8.txt' with the name of your file that has each common name on a row in the first column and the corresponding kingdom on the same row in the second column\n",
    "abbreviated_names_file = 'acronamesflipped-final.txt'\n",
    "# Trophic Keywords File: # To add keywords to the file, open the file and add your keywords to the phrases list as well as the specific category it would fall in\n",
    "trophic_keywords_file = 'trophickeywords-final.txt'\n",
    "# Random Forest training file\n",
    "random_forest_training_file = 'mixedtrain2.csv'\n",
    "# Ollie File\n",
    "ollie_file = 'ollie-app-latest.jar'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each imported library is used in a later step.\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "import nltk\n",
    "from itertools import groupby\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "import operator\n",
    "from itertools import groupby\n",
    "import argparse\n",
    "import subprocess\n",
    "from subprocess import PIPE, Popen\n",
    "import fitz\n",
    "import Levenshtein\n",
    "from Levenshtein import distance\n",
    "from more_itertools import unique_everseen\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:  Loading Necessary Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**English Word Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The collection of English words is saved as a list by reading the words from a file.\n",
    "english_list = []\n",
    "\n",
    "with open(english_dict_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        english_list.append(line)\n",
    "\n",
    "print('English dictionary loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scientific Names Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The collection of scientific names and kingdoms are saved as a dictionary by reading from a two columned file\n",
    "sci_names = []\n",
    "kingdom_names = []\n",
    "\n",
    "with open(sci_names_file, 'r') as data: \n",
    "    for line in data.readlines():\n",
    "        # Change the '\\t' delimiter to your file's delimiter if it isn't tab separated.\n",
    "        line = line.rstrip('\\n')\n",
    "        entity = line.split('\\t') \n",
    "        sci_names.append(entity[0])\n",
    "        kingdom_names.append(entity[1])\n",
    "# Lists are zipped together to create a dictionary.\n",
    "sci_name_dict = dict(zip(sci_names, kingdom_names))\n",
    "\n",
    "print('Scientific names loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Names Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The collection of common names and kingdoms are saved as a dictionary by reading from a two columned file\n",
    "common_names = []\n",
    "kingdom_names = []\n",
    "\n",
    "with open(common_names_file, 'r') as data: \n",
    "    for line in data.readlines():\n",
    "        # Change the '\\t' delimiter to your file's delimiter if it isn't tab separated.\n",
    "        line = line.rstrip('\\n')\n",
    "        entity = line.split('\\t') \n",
    "        common_names.append(entity[0])\n",
    "        kingdom_names.append(entity[1])\n",
    "# Lists are zipped together to create a dictionary.\n",
    "common_names_dict = dict(zip(common_names, kingdom_names))\n",
    "\n",
    "print('Common names loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abbreviated Scientific Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The collection of abbreviated names and expanded names are saved as a dictionary by reading from a two columned file\n",
    "abbreviated_names = []\n",
    "expanded_names = []\n",
    "\n",
    "with open(abbreviated_names_file, 'r') as data: \n",
    "    for line in data.readlines():\n",
    "        # Change the '\\t' delimiter to your file's delimiter if it isn't tab separated.\n",
    "        line = line.rstrip('\\n')\n",
    "        entity = line.split('\\t') \n",
    "        abbreviated_names.append(entity[0])\n",
    "        expanded_names.append(entity[1])\n",
    "        \n",
    "print('Abbreviated names loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trophic Keywords and Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The collection of trophic keywords and specific categories are saved as a dictionary by reading from a two columned file\n",
    "total_keywords_and_categories = []\n",
    "\n",
    "with open(trophic_keywords_file, 'r') as data: \n",
    "    for line in data.readlines():\n",
    "        # Change the '\\t' delimiter to your file's delimiter if it isn't tab separated.\n",
    "        line = line.rstrip('\\n')\n",
    "        category = line.split('\\t')\n",
    "        total_keywords_and_categories.append(category[1])\n",
    "\n",
    "total_keywords = ast.literal_eval(total_keywords_and_categories[0])\n",
    "lefttoright = ast.literal_eval(total_keywords_and_categories[1])\n",
    "righttoleft = ast.literal_eval(total_keywords_and_categories[2])\n",
    "reflexive = ast.literal_eval(total_keywords_and_categories[3])\n",
    "parasite = ast.literal_eval(total_keywords_and_categories[4])\n",
    "detritivore = ast.literal_eval(total_keywords_and_categories[5])\n",
    "\n",
    "print('Trophic categories loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file to train the classifier is read and its data is saved into an object\n",
    "mixedtraining3 = pd.read_csv(random_forest_training_file)\n",
    "# The data is cleaned, removing titles\n",
    "del mixedtraining3['name']\n",
    "X = mixedtraining3.iloc[:, 0:676].values\n",
    "y = mixedtraining3['type']\n",
    "# The classifier is trained\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "print('Random Forest model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Function with Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fucnction sci_check uses the trained Random Forest model from above to predict whether or not a term is a scientific word\n",
    "def sci_check(term):\n",
    "    entry = {}\n",
    "    all_columns = []\n",
    "    entry_frequencies = []\n",
    "    # Creating list of all possible bigrams\n",
    "    for char in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        all_possible_bigrams = [char+b for b in 'abcdefghijklmnopqrstuvwxyz']\n",
    "        all_columns.extend(all_possible_bigrams)\n",
    "        # Creating list of bigrams in term\n",
    "        chars = [term[i:i+2] for i in range(0, len(term))]\n",
    "    all_columns_2 = all_columns\n",
    "    # Count the frequency of the bigram in the term\n",
    "    for bigram in all_columns_2:\n",
    "        frequency = chars.count(bigram)\n",
    "        entry[bigram] = frequency\n",
    "        entry_frequencies.append(frequency)\n",
    "    # Use random forest model to check if it's a possible scientific name\n",
    "    y_pred = classifier.predict([entry_frequencies])\n",
    "    \n",
    "    return y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Function to Search Ollie Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function \"searching_ollie_results\" searches through Ollie results for relations that contain a keyword\n",
    "def searching_ollie_results(list_of_lists):\n",
    "    relevant_ollie_results = []\n",
    "    relevant_ollie_results_dict = {}\n",
    "    # Iterate through list of sentences and find sentences that have one of the food phrases\n",
    "    keep = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ.1234567890')\n",
    "    for ollie_relation in list_of_lists:\n",
    "        ollie_relation = ''.join(filter(keep.__contains__, str(ollie_relation)))\n",
    "        for keyword in total_keywords:\n",
    "            # Check if phrases are in sentences, the lowercasing both\n",
    "            if re.search(keyword.lower(), ollie_relation.lower()):\n",
    "                # Get the index of phrase in sentence\n",
    "                keyword_index = re.search(r'\\b({})\\b'.format(keyword.lower()), ollie_relation.lower())\n",
    "                # Check if index is equal to None\n",
    "                if keyword_index is not None:\n",
    "                    # Check if sentence already in results\n",
    "                    if ollie_relation not in relevant_ollie_results_dict.keys():\n",
    "                        # Add sentence and phrase into dictionary\n",
    "                        relevant_ollie_results_dict[ollie_relation] = keyword\n",
    "                        # Add sentence, phrase and indices to final results\n",
    "                        relevant_ollie_results.extend([[ollie_relation, keyword, [keyword_index.start(), keyword_index.end()]]])\n",
    "                        \n",
    "                    else:\n",
    "                        # If sentence already in result dictionary, save the previous entry\n",
    "                        smallest = min((relevant_ollie_results_dict[ollie_relation], keyword), key=len)\n",
    "                        # Check if smaller phrase is in longer phrase\n",
    "                        if smallest in keyword:\n",
    "                            # Save both phrases\n",
    "                            both = [relevant_ollie_results_dict[ollie_relation], keyword]\n",
    "                            # Keep the phrase that is the longest\n",
    "                            longest = max(both, key=len)\n",
    "                            # Find the index of the phrase\n",
    "                            keyword_index_2 = re.search(r'\\b({})\\b'.format(relevant_ollie_results_dict[ollie_relation].lower()), ollie_relation.lower())\n",
    "                            # Get the index of the previous entry from the results\n",
    "                            if [ollie_relation, relevant_ollie_results_dict[ollie_relation], [keyword_index_2.start(), keyword_index_2.end()]] in relevant_ollie_results:\n",
    "                                previous_index = relevant_ollie_results.index([ollie_relation, relevant_ollie_results_dict[ollie_relation], [keyword_index_2.start(), keyword_index_2.end()]])\n",
    "                            # Replace the previous results with the newer phrase entry\n",
    "                                relevant_ollie_results[previous_index] = [ollie_relation, longest, [keyword_index.start(), keyword_index.end()]]\n",
    "                        else:\n",
    "                            # If the phrases don't intersect, then extend the results with the new entry\n",
    "                            relevant_ollie_results.extend([[ollie_relation, keyword, [keyword_index.start(), keyword_index.end()]]])\n",
    "                            \n",
    "    # Remove duplicates from results\n",
    "    relevant_ollie_results = list(relevant_ollie_results for relevant_ollie_results,_ in itertools.groupby(relevant_ollie_results))\n",
    "    \n",
    "    return relevant_ollie_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Function to Identify Scientific Names and Add a Final Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function \"identify_and_classify\" takes the relevant trophic relations found by the \"searching_ollie_results\" function and locates scientific names while giving them a final classification\n",
    "def identify_and_classify(relevant_ollie_relations):\n",
    "    all_final_classifications = []\n",
    "    # Iterate through sentences of previous output\n",
    "    for i in range(0,len(relevant_ollie_relations)):\n",
    "        current_relation = []\n",
    "        words_in_official_scientific_name = []\n",
    "        words_added_to_current_relation = []\n",
    "        # Saving part of each result as a variable\n",
    "        sentence = relevant_ollie_relations[i][0]\n",
    "        phrase = relevant_ollie_relations[i][1]\n",
    "        words_added_to_current_relation.append(phrase)\n",
    "        current_relation.append(relevant_ollie_relations[i][1])\n",
    "        keyword_string_index = relevant_ollie_relations[i][2]\n",
    "        # Split by spaces\n",
    "        before_space = sentence[:keyword_string_index[0]].split()\n",
    "        after_space = sentence[keyword_string_index[0]:].split()\n",
    "        # Add a rule to check if word is a noun\n",
    "        is_noun = lambda pos: pos[:2] == 'NN'\n",
    "        # Finding nouns in sentence using the previously made rule\n",
    "        nouns = [word for (word, pos) in nltk.pos_tag(before_space+after_space) if is_noun(pos)]\n",
    "        nouns2 = nouns\n",
    "        words_in_english_dictionary = []\n",
    "        words_in_sci_name_list = []\n",
    "        # Checking if any of the nouns land in the dictionary\n",
    "        for word in nouns:\n",
    "            if word not in detritivore:\n",
    "                if word in english_list:\n",
    "                    words_in_english_dictionary.append(word)\n",
    "            # Check if word closely matches a word in list of scientific names\n",
    "            metric = (2, 'noname')\n",
    "            for master_name in sci_names:\n",
    "                new_metric = distance(word, master_name)\n",
    "                if (new_metric < metric[0]):\n",
    "                    metric = (new_metric, master_name)\n",
    "            if metric[1] == 'noname':\n",
    "                # Check if word is in abbreviated scientific names or common names\n",
    "                matching = [s for s in abbreviated_names + common_names if word in s]\n",
    "                if len(matching) > 0:\n",
    "                    metric = (0, metric[1])\n",
    "            if metric[0] < 2:\n",
    "                words_in_sci_name_list.append(word)\n",
    "        # Regular expressions of different forms of scientific names\n",
    "        patterns = ['[A-z]\\. [a-z]{3,}', '[A-Z][a-z]{4,}: [A-Z][a-z]{4,}', '[A-Z][a-z]{2,} [A-z]{3,}'] \n",
    "                #'[A-Z][a-z]{4,} [A-z]{4,}'\n",
    "        # Finding all regular expression matches in a sentence\n",
    "        located_patterns = []\n",
    "        for pattern in patterns:\n",
    "            searching_for_patterns = re.findall(pattern, relevant_ollie_relations[i][0])\n",
    "            located_patterns.extend(searching_for_patterns)\n",
    "        patterns_in_data_list = []\n",
    "        words_from_model = []\n",
    "        # Check if regular expression scientific name is closely related to a scientific name in the list\n",
    "        for located_word in located_patterns:\n",
    "            # Check if length of results is greater than 0 \n",
    "            metric = (2, 'noname')\n",
    "            for master_name in sci_names:\n",
    "                new_metric = distance(located_word, master_name)\n",
    "                if (new_metric < metric[0]):\n",
    "                    metric = (new_metric, master_name)\n",
    "            if metric[1] == 'noname':\n",
    "                # Check if word is in abbreviated scientific names or common names\n",
    "                matching = [s for s in abbreviated_names + common_names if located_word in s]\n",
    "                if len(matching) > 0 or '.' in located_word:\n",
    "                    metric = (0, metric[1])\n",
    "            if metric[0] < 2:\n",
    "                patterns_in_data_list.append(located_word)\n",
    "                input_1 = (located_word, 'scientificname')\n",
    "                # Check if word comes before or after the relational phrase in the sentence\n",
    "                if sentence.index(located_word) < sentence.lower().index(phrase):\n",
    "                    if current_relation.index(phrase) == 0: \n",
    "                        phrase_index = current_relation.index(phrase)\n",
    "                        current_relation.insert(0,input_1)\n",
    "                        words_added_to_current_relation.append(located_word)\n",
    "                    else:\n",
    "                        phrase_index = current_relation.index(phrase)\n",
    "                        current_relation.insert((phrase_index),input_1)\n",
    "                        words_added_to_current_relation.append(located_word)\n",
    "                else:\n",
    "                    phrase_index = current_relation.index(phrase)\n",
    "                    current_relation.index(phrase)\n",
    "                    current_relation.append(input_1)\n",
    "                    words_added_to_current_relation.append(located_word)\n",
    "            else:\n",
    "                # Test the located word against the model\n",
    "                test = sci_check(located_word)\n",
    "                input_test = [located_word, test]\n",
    "                if test.item() == 0:\n",
    "                    words_from_model.append(located_word)\n",
    "                    input_1 = (located_word, 'scientificname')\n",
    "                # If model says it is a scientific word, check if word comes before or after the relational phrase in the sentence\n",
    "                    if sentence.index(located_word) < sentence.lower().index(phrase):\n",
    "                        if current_relation.index(phrase) == 0: \n",
    "                            phrase_index = current_relation.index(phrase)\n",
    "                            current_relation.insert(0,input_1)\n",
    "                            words_added_to_current_relation.append(located_word)\n",
    "                        else:\n",
    "                            phrase_index = current_relation.index(phrase)\n",
    "                            current_relation.insert((phrase_index),input_1)\n",
    "                            words_added_to_current_relation.append(located_word)\n",
    "                    else:\n",
    "                        phrase_index = current_relation.index(phrase)\n",
    "                        current_relation.index(phrase)\n",
    "                        current_relation.append(input_1)\n",
    "                        words_added_to_current_relation.append(located_word)\n",
    "                \n",
    "        # Checking through nouns to see if any of them combined is a scientific name\n",
    "        if len(nouns) > 0:\n",
    "            for i in range(0, (len(nouns)-1)):\n",
    "                possible_scientific_word = nouns[i]+' '+nouns[i+1]\n",
    "                metric = (2, 'noname')\n",
    "                for master_name in sci_names:\n",
    "                    new_metric = distance(possible_scientific_word, master_name)\n",
    "                    if (new_metric < metric[0]):\n",
    "                        metric = (new_metric, master_name)\n",
    "                if metric[0] < 2 and metric[1] != 'noname':\n",
    "                    if possible_scientific_word in sentence:\n",
    "                        # Check if the the combination of the words is already in one of lists of scientific words that have already been found\n",
    "                        if any((possible_scientific_word in s for s in patterns_in_data_list + [', '.join(words_added_to_current_relation)])) == False:\n",
    "                            for each in possible_scientific_word.split():\n",
    "                                words_in_official_scientific_name.append(each)\n",
    "                            # Check if word came before or after phrase  \n",
    "                            if sentence.index(possible_scientific_word) < sentence.lower().index(phrase):\n",
    "                                phrase_index = current_relation.index(phrase)\n",
    "                                if phrase_index == 0:\n",
    "                                    input_1 = (possible_scientific_word, 'possiblescientificname')\n",
    "                                    current_relation.insert(0, input_1)\n",
    "                                    words_added_to_current_relation.append(possible_scientific_word)\n",
    "                                else:\n",
    "                                    phrase_index = current_relation.index(phrase)\n",
    "                                    input_1 = (possible_scientific_word, 'possiblescientificname')\n",
    "                                    current_relation.insert(phrase_index, input_1)\n",
    "                                    words_added_to_current_relation.append(possible_scientific_word)\n",
    "                            # Add word to the end because it comes after the phrase\n",
    "                            else:\n",
    "                                input_1 = (possible_scientific_word, 'possiblescientificname')\n",
    "                                current_relation.append(input_1)\n",
    "                                words_added_to_current_relation.append(possible_scientific_word)\n",
    "                    \n",
    "                else:\n",
    "                    # Split the possible scientific word into its parts and see if its in a list\n",
    "                    splitted = possible_scientific_word.split()\n",
    "                    # Check if substring is in the list of scientific names\n",
    "                    for substring in possible_scientific_word.split():\n",
    "                        metric = (2, 'noname')\n",
    "                        for master_name in sci_names:\n",
    "                            new_metric = distance(substring, master_name)\n",
    "                            if (new_metric < metric[0]):\n",
    "                                metric = (new_metric, substring)\n",
    "                        commonnamesfull = [x for x in detritivore]\n",
    "                        # Check if the substring has already been added or checked\n",
    "                        if metric[1] != 'noname':\n",
    "                            if substring not in ', '.join(patterns_in_data_list + words_from_model).split() + (' '.join(words_added_to_current_relation)).split():\n",
    "                                input_1 = (substring, 'scientificname')\n",
    "                                # If the substring has not already been added, check if it comes before or after the phrase\n",
    "                                if substring.lower() not in english_list and len(substring) > 2:\n",
    "                                    if sentence.index(substring) < sentence.lower().index(phrase):\n",
    "                                        phrase_index = current_relation.index(phrase)\n",
    "                                        if phrase_index == 0:\n",
    "                                            current_relation.insert(0, input_1)\n",
    "                                            words_added_to_current_relation.append(substring)\n",
    "                                        else:\n",
    "                                            phrase_index = current_relation.index(phrase)\n",
    "                                            current_relation.insert(phrase_index, input_1)\n",
    "                                            words_added_to_current_relation.append(substring)\n",
    "                                    # Add the substring to the end if the word comes after the phrase      \n",
    "                                    else:\n",
    "                                        words_added_to_current_relation.append(substring)\n",
    "                                        current_relation.append(input_1)\n",
    "                                else:\n",
    "                                    dictionaryterm = substring\n",
    "                        # Check if it is in the list of common names in the detritivore category\n",
    "                        elif any(substring in s for s in commonnamesfull):\n",
    "                            if substring not in ', '.join(words_added_to_current_relation):\n",
    "                                input_1 = (substring, 'common scientificname')\n",
    "                                # Check if word comes before or after the phrase\n",
    "                                if sentence.index(substring) < sentence.lower().index(phrase):\n",
    "                                    phrase_index = current_relation.index(phrase)\n",
    "                                    if phrase_index == 0:\n",
    "                                        current_relation.insert(0, input_1)\n",
    "                                        words_added_to_current_relation.append(substring)\n",
    "                                    else:\n",
    "                                        phrase_index = current_relation.index(phrase)\n",
    "                                        current_relation.insert(phrase_index, input_1)\n",
    "                                        words_added_to_current_relation.append(substring)\n",
    "                                else:\n",
    "                                    current_relation.append(input_1)\n",
    "                                    words_added_to_current_relation.append(substring)\n",
    "                            \n",
    "                        else:\n",
    "                            # Check if word is a scientific word based on the model\n",
    "                            test = sci_check(substring)\n",
    "                            input_test = [substring, test]\n",
    "                            if test.item() == 0:\n",
    "                                words_from_model.append(substring)\n",
    "                                # Add possible scientific name if not in previously added lists\n",
    "                                if substring not in (' '.join(patterns_in_data_list)).split():\n",
    "                                    if substring not in ', '.join(words_added_to_current_relation):\n",
    "                                        if substring not in english_list:\n",
    "                                            input_1 = (substring, 'possiblescientificname')\n",
    "                                            if sentence.index(substring) < sentence.lower().index(phrase):\n",
    "                                                phrase_index = current_relation.index(phrase)\n",
    "                                                if phrase_index == 0:\n",
    "                                                    current_relation.insert(0, input_1)\n",
    "                                                    words_added_to_current_relation.append(substring)\n",
    "                                                else:\n",
    "                                                    phrase_index = current_relation.index(phrase)\n",
    "                                                    current_relation.insert(phrase_index, input_1)\n",
    "                                                    words_added_to_current_relation.append(substring)\n",
    "                                            else:\n",
    "                                                phrase_index = current_relation.index(phrase)\n",
    "                                                current_relation.append(input_1)\n",
    "                                                words_added_to_current_relation.append(substring)\n",
    "                                \n",
    "                            \n",
    "        # Using categories of directionality to figure out sentence classification                       \n",
    "        current_relation = [x[0] for x in groupby(current_relation)]\n",
    "        phrase_index = current_relation.index(phrase)\n",
    "        classifications_and_relation = []\n",
    "        if any('scientificname' in part or 'possiblescientificname' in part or 'common scientificname' in part for part in current_relation):\n",
    "            if len(current_relation) > 2:\n",
    "                # Separate sentences based on before and after phrase\n",
    "                classifications_and_relation.append(sentence)\n",
    "                words_after_phrase = [nm for nm in current_relation[phrase_index:] if 'scientificname' in nm[1]]\n",
    "                words_before_phrase = [nm for nm in current_relation[:phrase_index] if 'scientificname' in nm[1]]\n",
    "                # Check if phrase in lefttoright and if there is a word after the phrase\n",
    "                if phrase in lefttoright and (phrase_index+1) < len(current_relation):\n",
    "                    # Check if word in scientific name list or common name list or abbreviated name list\n",
    "                    for k in range(0, len(words_after_phrase)):\n",
    "                        final_result = 'default'\n",
    "                        word = words_after_phrase[k][0]\n",
    "                        if word not in detritivore:\n",
    "                            metric = (2, 'noname')\n",
    "                            for master_name in sci_names:\n",
    "                                new_metric = distance(word, master_name)\n",
    "                                if (new_metric < metric[0]):\n",
    "                                    metric = (new_metric, master_name)\n",
    "                            if metric[1] == 'noname':\n",
    "                                # Check if word in common name list\n",
    "                                matching = [s for s in common_names if word in s]\n",
    "                                if len(matching) > 0:\n",
    "                                    metric = (0, metric[1]) \n",
    "                                    kept = min(matching, key=len)\n",
    "                                    final_result = common_names_dict[min(matching, key=len)]\n",
    "                                    metric = list(metric)\n",
    "                                    metric[1] = min(matching, key=len)\n",
    "                                else:\n",
    "                                    # Check if word in abbreviated name list\n",
    "                                    matching = [s for s in abbreviated_names if word in s]\n",
    "                                    if len(matching) > 0:\n",
    "                                        final_result = 'not available'\n",
    "                            else:\n",
    "                                if metric[0] < 2:\n",
    "                                    final_result = sci_name_dict[metric[1]]\n",
    "                                else:\n",
    "                                    final_result = 'none'\n",
    "                        # Check if words in sentence are in the parasite list of words\n",
    "                        sentencesplit = sentence.split()\n",
    "                        parasite_testing = [x for x in parasite if x in sentence]\n",
    "                        # If parasite words are in sentence, add parasite classification\n",
    "                        if len(parasite_testing)>0:\n",
    "                            for i in range(0, len(words_before_phrase)):\n",
    "                                classifications_and_relation.append(str(words_before_phrase[i][0] + \" is a parasite\" + \" - \" + ', '.join(parasite_testing)))\n",
    "                        # Check if Animalia is in the kingdom designation \n",
    "                        elif 'Animalia' in str(final_result):\n",
    "                            for i in range(0, len(words_before_phrase)):\n",
    "                                classifications_and_relation.append( str(words_before_phrase[i][0] + \" is a carnivore\" + ' - ' + metric[1]))\n",
    "                                # If Animalia and Herbivore is in classification then omnivore classification is added\n",
    "                                if str(words_before_phrase[i][0]) + ' is a herbivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_before_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                        # Check if Plantae is in the kingdom designation\n",
    "                        elif 'Plantae' in str(final_result):\n",
    "                            for i in range(0, len(words_before_phrase)):\n",
    "                                classifications_and_relation.append(str(words_before_phrase[i][0] + \" is a herbivore\" + ' - ' + metric[1]))\n",
    "                                # If Animalia and Herbivore is in classification then omnivore classification is added\n",
    "                                if str(words_before_phrase[i][0]) + ' is a carnivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_before_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                        # Check if word is in detritivore list\n",
    "                        elif word in detritivore:\n",
    "                            for i in range(0, len(words_before_phrase)):\n",
    "                                # Add the detritivore classification\n",
    "                                classifications_and_relation.append(str(words_before_phrase[i][0] + \" is a detritivore\" + ' - ' + word))\n",
    "                        else:\n",
    "                            tag = 'sentence of interest'\n",
    "                # If phrase in detritivore and right to left, the word after the phrase is classified\n",
    "                elif phrase in detritivore and phrase in righttoleft:\n",
    "                    for k in range(0, len(words_after_phrase)):\n",
    "                        # Add detritivore classification\n",
    "                        classifications_and_relation.append(str(words_after_phrase[k][0] + \" is a detritivore\" + ' - ' + phrase))\n",
    "                # Check if phrase in righttoleft and if there is a word after the phrase\n",
    "                elif phrase in righttoleft and (phrase_index+1) < len(current_relation):\n",
    "                    # Check if word in scientific name list or common name list or abbreviated name list\n",
    "                    for k in range(0, len(words_before_phrase)):   \n",
    "                        final_result = 'default'\n",
    "                        word = words_before_phrase[k][0]\n",
    "                        if word not in detritivore:\n",
    "                            metric = (2, 'noname')\n",
    "                            for master_name in sci_names:\n",
    "                                new_metric = distance(word, master_name)\n",
    "                                if (new_metric < metric[0]):\n",
    "                                    metric = (new_metric, master_name)\n",
    "                            # Check if word in common name list\n",
    "                            if metric[1] == 'noname':\n",
    "                                matching = [s for s in common_names if word in s]\n",
    "                                if len(matching) > 0:\n",
    "                                    metric = (0, metric[1])\n",
    "                                    kept = (min(matching, key=len))\n",
    "                                    final_result = common_names_dict[min(matching, key=len)]\n",
    "                                    metric = list(metric)\n",
    "                                    metric[1] = kept\n",
    "                                # Check if word in abbreviated name list\n",
    "                                else:\n",
    "                                    matching = [s for s in abbreviated_names if word in s]\n",
    "                                    if len(matching) > 0:\n",
    "                                        final_result = 'not available'\n",
    "                            else:\n",
    "                                if metric[0] < 2:\n",
    "                                    final_result = sci_name_dict[metric[1]]\n",
    "                                else:\n",
    "                                    final_result = 'none'\n",
    "                        # Check if words in sentence are in the parasite list of words\n",
    "                        sentencesplit = sentence.split()\n",
    "                        parasite_testing = [x for x in parasite if x in sentence]\n",
    "                        # If parasite words are in sentence, add parasite classification\n",
    "                        if len(parasite_testing)>0:\n",
    "                            for i in range(0, len(words_after_phrase)):\n",
    "                                classifications_and_relation.append(str(words_after_phrase[i][0] + \" is a parasite\" + ' - ' + ', '.join(parasite_testing)))\n",
    "                        # Check if Animalia is in the kingdom designation\n",
    "                        elif 'Animalia' in str(final_result):\n",
    "                            for i in range(0, len(words_after_phrase)):\n",
    "                                classifications_and_relation.append( str(words_after_phrase[i][0] + \" is a carnivore\" + ' - ' + metric[1]))\n",
    "                                # If Animalia and Herbivore is in classification then omnivore classification is added\n",
    "                                if str(words_before_phrase[i][0]) + ' is a herbivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_after_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                        # Check if Plantae is in the kingdom designation\n",
    "                        elif 'Plantae' in str(final_result):\n",
    "                            for i in range(0, len(words_after_phrase)):\n",
    "                                classifications_and_relation.append(str(words_after_phrase[i][0] + \" is a herbivore\" + ' - ' + metric[1]))\n",
    "                                # If Animalia and Herbivore is in classification then omnivore classification is added\n",
    "                                if str(words_after_phrase[i][0]) + ' is a carnivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_after_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                        # Check if word is in detritivore list\n",
    "                        elif word in detritivore:\n",
    "                            for i in range(0, len(words_after_phrase)):\n",
    "                                # Add the detritivore classification\n",
    "                                classifications_and_relation.append(str(words_after_phrase[i][0] + \" is a detritivore\" + ' - ' + word))\n",
    "                        else:\n",
    "                            tag = 'sentence of interest'\n",
    "                # Check if phrase is in list of reflexive keywords\n",
    "                elif phrase in reflexive.keys():\n",
    "                    words_before_phrase = [nm for nm in current_relation[:phrase_index] if 'scientificname' in nm[1]]\n",
    "                    words_after_phrase = [nm for nm in current_relation[phrase_index:] if 'scientificname' in nm[1]]\n",
    "                    # Check if there is more nouns before or after the keywords\n",
    "                    if len(words_after_phrase) > len(words_before_phrase):\n",
    "                        #Iterate through words after phrase and classify\n",
    "                        for i in range(0, len(words_after_phrase)):\n",
    "                            # Add omnivore classification\n",
    "                            if reflexive[phrase] == 'omnivore':\n",
    "                                classifications_and_relation.append(str(words_after_phrase[i][0] + ' is an ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                            # Add herbivore classification\n",
    "                            elif reflexive[phrase] == 'herbivore':\n",
    "                                classifications_and_relation.append(str(words_after_phrase[i][0] + ' is a ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                                # Add omnivore classification if carnivore and herbivore classification are present\n",
    "                                if str(words_after_phrase[i][0]) + ' is a carnivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_after_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                            # Add carnivore classification\n",
    "                            elif reflexive[phrase] == 'carnivore':\n",
    "                                classifications_and_relation.append(str(words_after_phrase[i][0] + ' is a ' + reflexive[phrase] +  ' - ' + phrase))\n",
    "                                # Add omnivore classification if carnivore and herbivore classification are present\n",
    "                                if str(words_after_phrase[i][0]) + ' is a herbivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_after_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                            else:\n",
    "                                classifications_and_relation.append(str(words_after_phrase[i][0] + ' is a ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                    else:\n",
    "                        # Iterate through list of words before phrase\n",
    "                        for i in range(0, len(words_before_phrase)):\n",
    "                            # Add omnivore classification\n",
    "                            if reflexive[phrase] == 'omnivore':\n",
    "                                classifications_and_relation.append(str(words_before_phrase[i][0] + ' is an ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                            # Add herbivore classification\n",
    "                            elif reflexive[phrase] == 'herbivore':\n",
    "                                classifications_and_relation.append(str(words_before_phrase[i][0] + ' is a ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                                # Add omnivore classification if carnivore and herbivore classification are present\n",
    "                                if str(words_before_phrase[i][0]) + ' is a carnivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_before_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                            # Add carnivore classification\n",
    "                            elif reflexive[phrase] == 'carnivore':\n",
    "                                classifications_and_relation.append(str(words_before_phrase[i][0] + ' is a ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                                # Add omnivore classification if carnivore and herbivore classification are present\n",
    "                                if str(words_before_phrase[i][0]) + ' is a herbivore' in classifications_and_relation:\n",
    "                                    classifications_and_relation.append( str(words_before_phrase[i][0] + \" is an omnivore\" + ' - ' + 'Herb+Carn'))\n",
    "                            else:\n",
    "                                classifications_and_relation.append(str(words_before_phrase[i][0] + ' is a ' + reflexive[phrase]))\n",
    "                    \n",
    "            # If length of relation and scientific name is equal to two\n",
    "            elif len(current_relation) == 2:\n",
    "                words_before_phrase = [nm for nm in current_relation[:phrase_index] if 'scientificname' in nm[1]]\n",
    "                words_after_phrase = [nm for nm in current_relation[phrase_index:] if 'scientificname' in nm[1]]\n",
    "                classifications_and_relation.append(sentence)\n",
    "                # Add final classification depending on if phrase comes before or after scientific name\n",
    "                if phrase in reflexive.keys() and current_relation.index(phrase) == 1:\n",
    "                    for i in range(0, len(words_before_phrase)):\n",
    "                        classifications_and_relation.append(str(words_before_phrase[i][0] + ' is an ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                elif phrase in reflexive.keys() and current_relation.index(phrase) == 0:\n",
    "                    for i in range(0, len(words_after_phrase)):\n",
    "                        classifications_and_relation.append(str(words_after_phrase[i][0] + ' is an ' + reflexive[phrase] + ' - ' + phrase))\n",
    "                elif phrase in detritivore and phrase in righttoleft:\n",
    "                    for k in range(0, len(words_after_phrase)):\n",
    "                        classifications_and_relation.append(current_relation[1][0] + \" is a detritivore\" + ' - ' + phrase)\n",
    "                else:\n",
    "                    tag = 'Sentence of interest'   \n",
    "            else:\n",
    "                tag = 'Sentence of interest'\n",
    "        \n",
    "        # Check if length of input is greater than one\n",
    "        if len(classifications_and_relation)>1:\n",
    "            # Remove duplicates\n",
    "            classifications_and_relation = list(unique_everseen(classifications_and_relation))\n",
    "            # Add relation and classifications to overall list\n",
    "            all_final_classifications.append(classifications_and_relation)\n",
    "                \n",
    "        \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "                \n",
    "    return all_final_classifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Function to Clean Results and Output to a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that cleans results and outputs it to a file\n",
    "def send_classifications_to_file(classifications, output_file_name, analyzed_file_name):\n",
    "    # Creating list for triplets to be written to file\n",
    "    final_classification_triplets = []\n",
    "    # Adding the name of the analyzed file\n",
    "    final_classification_triplets.append((analyzed_file_name, '--', '--'))\n",
    "    # Iterating through the final classification for each relation\n",
    "    for classification in classifications:\n",
    "        # Creating a list of the final classifications for each relation\n",
    "        categories = [x.split('-')[0] for x in classification[1:]]\n",
    "        # Iterating through each final classification\n",
    "        for classified_noun in list(set(categories)):\n",
    "            # Creating a list of the decider(s) for each classification\n",
    "            duplicate_classifications = [y.split('-')[1].strip() for x in classifications for y in x if classified_noun in y]\n",
    "            # Adding a triplet of the relation, the noun classified and the decider to the list of triplets\n",
    "            final_classification_triplets.append((classification[0].strip(), classified_noun.strip(), list(set(duplicate_classifications))))\n",
    "    # Writing to a file by checking first if it exists\n",
    "    if os.path.isfile(output_file) == False:\n",
    "    # Adding a triplet that represents the header to the triplet list\n",
    "        final_classification_triplets.insert(0, ('Ollie Relation', 'Final Classification', 'Classification Decider'))\n",
    "        with open(output_file, 'w') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerows(final_classification_triplets)\n",
    "    else:\n",
    "        # Appending to a file if it is already exists\n",
    "        with open(output_file, 'a') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerows(final_classification_triplets)\n",
    "    \n",
    "    return 'Outputs written to file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Analyzing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through list of files to be analyzed\n",
    "print('Analyzing files')\n",
    "for file in files_to_be_analyzed:\n",
    "    print(file)\n",
    "    extracted_text = ''\n",
    "    # Open the file\n",
    "    document = fitz.open(file) \n",
    "    # Iterate through pages in the file\n",
    "    for page in document:\n",
    "        # Extract the text from each page in the document\n",
    "        texts = page.getText('text')\n",
    "        # Add the extracted text to the text object\n",
    "        extracted_text = extracted_text + texts\n",
    "    # Replace dashes in the extracted text\n",
    "    extracted_text = extracted_text.replace(\" -\", \"\")\n",
    "    extracted_text = extracted_text.replace(\" - \", \"\")\n",
    "    extracted_text = extracted_text.replace(\"- \", \"\")\n",
    "    # Split the extracted text where it says References and take all the text above\n",
    "    extracted_text = extracted_text.split(\"References\",maxsplit=1)[0]\n",
    "    # Extracted text file name\n",
    "    extracted_text_file_name = file.split('.')[0] + '-extracted-text.txt'\n",
    "    # Ollie extractions file name\n",
    "    relation_file_name = file.split('.')[0] + '-relations.txt'\n",
    "    # Adding a new line between every sentence\n",
    "    text_with_new_lines = re.sub(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', '\\n', extracted_text)\n",
    "    # Replacing newlines between lowercase characters with a single space\n",
    "    replace_new_lines_between_lowercase_characters = re.sub(r'(\\n+)(?=[a-z])', \" \", text_with_new_lines)\n",
    "    # Save the extracted text to a file\n",
    "    with open(extracted_text_file_name, 'w') as out:\n",
    "        out.write(replace_new_lines_between_lowercase_characters)\n",
    "    # Save the Ollie extractions to a file\n",
    "    with open(relation_file_name, 'w') as f:\n",
    "        # Running the Ollie tool on the extracted text file\n",
    "        subprocess.run([\"java\", \"-Xmx512m\", \"-jar\", ollie_file, extracted_text_file_name], stdout=f)\n",
    "    # Opening the files with relations\n",
    "    with open(relation_file_name) as f:\n",
    "        relations = []\n",
    "        for line in f:\n",
    "            # Iterating through relations and extracting lines that start with a confidence score\n",
    "            if re.match(r\"^\\d+.*$\",line):\n",
    "                # Adding the found lines to the relations list\n",
    "                relations.append(line)\n",
    "        # Replace characters and spaces added by Ollie\n",
    "        relations = [relation.replace(\"\\n\", \"\") for relation in relations]\n",
    "        relations = [relation.replace(\")[enabler\", \", \") for relation in relations]\n",
    "        relations = [relation.replace(\")[\", \", \") for relation in relations]\n",
    "        relations = [relation.replace(\"attrib=\", \" attribute \")]\n",
    "        # Search through relations for keywords\n",
    "        relations_with_keyword = searching_ollie_results(relations)\n",
    "        print(relations_with_keyword)\n",
    "        # Analyze relations and add a final classification\n",
    "        classifications = identify_and_classify(relations_with_keyword)\n",
    "        print(classifications)\n",
    "        # Writing the classifications to a file\n",
    "        send_classifications_to_file(classifications, output_file, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
